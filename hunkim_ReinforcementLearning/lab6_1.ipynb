{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state를 표현하기 위해 one-hot encoding을 사용\n",
    "\n",
    "state : np.identity(16)[s1:s1 +1] 과 같은 형태로 한 번에 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.identity(16)[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.eye(16)[10:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.identity(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x):\n",
    "    return np.identity(16)[x:x+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output siza based on the Env\n",
    "input_size = env.observation_space.n # 4\n",
    "output_size = env.action_space.n # 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These lines establish the feed-forward part of the network used to choose actions\n",
    "X = tf.placeholder(shape=[1, input_size], dtype=tf.float32) # state input\n",
    "W = tf.Variable(tf.random_uniform([input_size, output_size], 0, 0.01)) # weight\n",
    "\n",
    "Qpred = tf.matmul(X, W) # out Q prediction\n",
    "Y = tf.placeholder(shape=[1, output_size], dtype=tf.float32) # Y label\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(Y-Qpred))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Q-learning related parameters\n",
    "dis = 0.99\n",
    "num_episodes = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) # init = tf.global_variables_initializer() \n",
    "    for i in range(num_episodes):\n",
    "        # Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        e = 1.0 / ( (i / 50) + 10 )\n",
    "        rAll = 0\n",
    "        done = False\n",
    "        local_loss = []\n",
    "        \n",
    "        # The Q-Network training\n",
    "        while not done:\n",
    "            # Choose an action by greedily (with e chance of ramdom action) from the Q-network\n",
    "            Qs = sess.run(Qpred, feed_dict={X: one_hot(s)}) # just table -> network\n",
    "            if np.random.rand(1) < e :\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = np.argmax(Qs)\n",
    "\n",
    "            # Get new state and reward from environment\n",
    "            s1, reward, done, _ = env.step(a)\n",
    "            # Terminal or not\n",
    "            if done:\n",
    "                # Update Q, and no Qs+1, since it's a terminal state\n",
    "                Qs[0, a] = reward\n",
    "            else:\n",
    "                # Obtain the Q_s1 values by feeding the new state through our network\n",
    "                Qs1 = sess.run(Qpred, feed_dict={X: one_hot(s1)})\n",
    "                # Update Q\n",
    "                Qs[0, a] = reward + dis * np.max(Qs1)\n",
    "\n",
    "            # Train out network using target (Y) and predicted Q (Qpred) values\n",
    "            sess.run(train, feed_dict = {X: one_hot(s), Y: Qs})\n",
    "\n",
    "            rAll += reward\n",
    "            s = s1\n",
    "        rList.append(rAll)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of successful episodes: 0.4535%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEEBJREFUeJzt3X+sZGddx/H3hy7FCAWKezFNd8suuhg3xNh6U2sQxFBh2+CuP5Bso6Fiw8aEqgQ0ltRUUv8CoiTECtbQ8CNAKSiyMUsKwSrG0NpbaEu3ZentUuza2i6lFgxCqX79Y87CdDpz58y9c+9ln7xfyeSe85xnzvnOc8589twzd86mqpAkteUpm12AJGn+DHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSg7Zs1oa3bt1aO3bs2KzNS9JJ6ZZbbvlaVS1M67dp4b5jxw6WlpY2a/OSdFJK8tU+/bwsI0kNMtwlqUGGuyQ1yHCXpAYZ7pLUoKnhnuSaJA8luWPC8iR5Z5LlJLcnOWf+ZUqSZtHnzP29wJ4Vll8A7OoeB4B3rb0sSdJaTA33qvos8PUVuuwD3l8DNwLPTnLGvAqUJM1uHtfczwTuG5o/1rVJkjbJPMI9Y9rG/q/bSQ4kWUqydPz48bVvOIPHSsv7Pm+l9cxa01qfN1zfSnWO9hn3nEnTk543rv7R9km1jXveSnWNvs5xbeP6r2Xf9X3N45b1Od4m1Tip1nGvfy11rDSO05ZNqnWlZZPaVhrfaePUd3/26beW98u45/U9RldaNq+smWYe4X4M2D40vw24f1zHqrq6qharanFhYeqtESRJqzSPcD8IvKb7q5nzgEer6oE5rFeStEpTbxyW5MPAS4GtSY4Bfwo8FaCq3g0cAi4EloFvAa9dr2IlSf1MDfequmjK8gJeP7eKJElr5jdUJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ3qFe5J9iQ5kmQ5yWVjlp+V5IYkX0hye5IL51+qJKmvqeGe5BTgKuACYDdwUZLdI93+BLiuqs4G9gN/Ne9CJUn99TlzPxdYrqqjVfUYcC2wb6RPAc/spp8F3D+/EiVJs9rSo8+ZwH1D88eAnx3p8xbgU0l+D3g6cP5cqpMkrUqfM/eMaauR+YuA91bVNuBC4ANJnrTuJAeSLCVZOn78+OzVSpJ66RPux4DtQ/PbePJll0uA6wCq6nPADwFbR1dUVVdX1WJVLS4sLKyuYknSVH3C/WZgV5KdSU5l8IHpwZE+/w68DCDJTzIId0/NJWmTTA33qnocuBS4HriLwV/FHE5yZZK9Xbc3Aa9LchvwYeC3q2r00o0kaYP0+UCVqjoEHBppu2Jo+k7gRfMtTZK0Wn5DVZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGtQr3JPsSXIkyXKSyyb0eXWSO5McTvKh+ZYpSZrFlmkdkpwCXAX8EnAMuDnJwaq6c6jPLuDNwIuq6pEkz12vgiVJ0/U5cz8XWK6qo1X1GHAtsG+kz+uAq6rqEYCqemi+ZUqSZtEn3M8E7huaP9a1DXsB8IIk/5rkxiR75lWgJGl2Uy/LABnTVmPWswt4KbAN+JckL6yq/3rCipIDwAGAs846a+ZiJUn99DlzPwZsH5rfBtw/ps8nquq7VfUV4AiDsH+Cqrq6qharanFhYWG1NUuSpugT7jcDu5LsTHIqsB84ONLn74FfBEiylcFlmqPzLFSS1N/UcK+qx4FLgeuBu4DrqupwkiuT7O26XQ88nORO4Abgj6rq4fUqWpK0sj7X3KmqQ8ChkbYrhqYLeGP3kCRtMr+hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWpQr3BPsifJkSTLSS5bod+rklSSxfmVKEma1dRwT3IKcBVwAbAbuCjJ7jH9TgN+H7hp3kVKkmbT58z9XGC5qo5W1WPAtcC+Mf3+DHgb8O051idJWoU+4X4mcN/Q/LGu7XuSnA1sr6p/mGNtkqRV6hPuGdNW31uYPAV4B/CmqStKDiRZSrJ0/Pjx/lVKkmbSJ9yPAduH5rcB9w/Nnwa8EPinJPcC5wEHx32oWlVXV9ViVS0uLCysvmpJ0or6hPvNwK4kO5OcCuwHDp5YWFWPVtXWqtpRVTuAG4G9VbW0LhVLkqaaGu5V9ThwKXA9cBdwXVUdTnJlkr3rXaAkaXZb+nSqqkPAoZG2Kyb0fenay5IkrYXfUJWkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb1Cvcke5IcSbKc5LIxy9+Y5M4ktyf5TJLnzb9USVJfU8M9ySnAVcAFwG7goiS7R7p9AVisqp8CPga8bd6FSpL663Pmfi6wXFVHq+ox4Fpg33CHqrqhqr7Vzd4IbJtvmZKkWfQJ9zOB+4bmj3Vtk1wCfHLcgiQHkiwlWTp+/Hj/KiVJM+kT7hnTVmM7Jr8FLAJvH7e8qq6uqsWqWlxYWOhfpSRpJlt69DkGbB+a3wbcP9opyfnA5cAvVNV35lOeJGk1+py53wzsSrIzyanAfuDgcIckZwN/DeytqofmX6YkaRZTw72qHgcuBa4H7gKuq6rDSa5Msrfr9nbgGcBHk9ya5OCE1UmSNkCfyzJU1SHg0EjbFUPT58+5LknSGvgNVUlqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDeoV7kj1JjiRZTnLZmOVPS/KRbvlNSXbMu1BJUn9Twz3JKcBVwAXAbuCiJLtHul0CPFJVPw68A3jrvAuVJPXX58z9XGC5qo5W1WPAtcC+kT77gPd10x8DXpYk8ytTkjSLPuF+JnDf0Pyxrm1sn6p6HHgU+JF5FChJmt2WHn3GnYHXKvqQ5ABwoJv97yRHemx/nK3A176/3skdZ1k2h981tgJfW+16JtWzUp2jfcY9J/n+ePXZxqT6V9ruJCvVxQrjNW39a9l3PV7zisdX322ttvYpz5u4L1faVp8xnnU/TNuXfY6pnuue6bkjtiZP3pdT3i8z1bjK4/cJx9iMntenU59wPwZsH5rfBtw/oc+xJFuAZwFfH11RVV0NXN2nsJUkWaqqxbWuZ96sazbWNbsf1NqsazYbUVefyzI3A7uS7ExyKrAfODjS5yBwcTf9KuAfq+pJZ+6SpI0x9cy9qh5PcilwPXAKcE1VHU5yJbBUVQeB9wAfSLLM4Ix9/3oWLUlaWZ/LMlTVIeDQSNsVQ9PfBn5jvqWtaM2XdtaJdc3Gumb3g1qbdc1m3euKV08kqT3efkCSGnTShfu0WyGs87a3J7khyV1JDif5g679LUn+I8mt3ePCoee8uav1SJJXrGNt9yb5Yrf9pa7tOUk+neTu7ufpXXuSvLOr6/Yk56xTTT8xNCa3JvlGkjdsxngluSbJQ0nuGGqbeXySXNz1vzvJxeO2NYe63p7kS922P57k2V37jiT/MzRu7x56zs90+3+5q31Nf9g7oa6Z99u8368T6vrIUE33Jrm1a9/I8ZqUDZt3jFXVSfNg8IHuPcDzgVOB24DdG7j9M4BzuunTgC8zuCXDW4A/HNN/d1fj04CdXe2nrFNt9wJbR9reBlzWTV8GvLWbvhD4JIPvJ5wH3LRB++4/GfyN7oaPF/AS4BzgjtWOD/Ac4Gj38/Ru+vR1qOvlwJZu+q1Dde0Y7jeynn8Dfq6r+ZPABetQ10z7bT3er+PqGln+58AVmzBek7Jh046xk+3Mvc+tENZNVT1QVZ/vpr8J3MWTv607bB9wbVV9p6q+AiwzeA0bZfi2EO8DfmWo/f01cCPw7CRnrHMtLwPuqaqvrtBn3carqj7Lk797Mev4vAL4dFV9vaoeAT4N7Jl3XVX1qRp80xvgRgbfLZmoq+2ZVfW5GiTE+4dey9zqWsGk/Tb39+tKdXVn368GPrzSOtZpvCZlw6YdYydbuPe5FcKGyODOl2cDN3VNl3a/Xl1z4lcvNrbeAj6V5JYMvgkM8KNV9QAMDj7guZtQ1wn7eeKbbrPHC2Yfn80Yt99hcIZ3ws4kX0jyz0le3LWd2dWyEXXNst82erxeDDxYVXcPtW34eI1kw6YdYydbuPe6zcG6F5E8A/hb4A1V9Q3gXcCPAT8NPMDgV0PY2HpfVFXnMLh75+uTvGSFvhs6jhl8+W0v8NGu6QdhvFYyqY6NHrfLgceBD3ZNDwBnVdXZwBuBDyV55gbWNet+2+j9eRFPPIHY8PEakw0Tu06oYW61nWzh3udWCOsqyVMZ7LwPVtXfAVTVg1X1v1X1f8Df8P1LCRtWb1Xd3/18CPh4V8ODJy63dD8f2ui6OhcAn6+qB7saN328OrOOz4bV132Q9krgN7tLB3SXPR7upm9hcD37BV1dw5du1qWuVey3jRyvLcCvAR8ZqndDx2tcNrCJx9jJFu59boWwbrpreu8B7qqqvxhqH75e/avAiU/yDwL7M/jPTHYCuxh8kDPvup6e5LQT0ww+kLuDJ94W4mLgE0N1vab7xP484NETvzqukyecUW32eA2ZdXyuB16e5PTuksTLu7a5SrIH+GNgb1V9a6h9IYP/X4Ekz2cwPke72r6Z5LzuGH3N0GuZZ12z7reNfL+eD3ypqr53uWUjx2tSNrCZx9haPiHejAeDT5m/zOBf4cs3eNs/z+BXpNuBW7vHhcAHgC927QeBM4aec3lX6xHW+In8CnU9n8FfItwGHD4xLgxuu/wZ4O7u53O69jD4D1ju6epeXMcx+2HgYeBZQ20bPl4M/nF5APgug7OjS1YzPgyugS93j9euU13LDK67njjG3t31/fVu/94GfB745aH1LDII23uAv6T7guKc65p5v837/Tqurq79vcDvjvTdyPGalA2bdoz5DVVJatDJdllGktSD4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoP+H7JT1hdBdLANAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a29b31668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Percent of successful episodes: \" + str(sum(rList)/num_episodes) + \"%\")\n",
    "plt.bar(range(len(rList)), rList, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "* Too slow\n",
    "    - Minibatch?\n",
    "\n",
    "\n",
    "* A bit unstable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
