{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5. Q-Learning in non-deterministic world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic(Nondeterministic) = Action을 했을때 항상 똑같은 State와 Reward가 오는것이 아님.\n",
    "Deterministic : 특정 State에서 어떤 action을 했을때 항상 같은 State와 Reward가 반환 됨.\n",
    "\n",
    "Stochastic (non-deterministic) world\n",
    "- solution?  \n",
    "    Listen to Q(s') (just a little bit)  \n",
    "    Update Q(s) little bit (learning rate)  \n",
    "- Like our life mentors  \n",
    "    Don't just listen and follow one mentor  \n",
    "    Need to listen from many mentors  \n",
    "\n",
    "Stochastic하기 때문에 Q'의 값을 줄여서 반영함(little bit 의견) using alpha\n",
    "Q^(hat)(s, a) <- (1 - alpha)Q^(hat)(s, a) + alpha[r + gamma\\*max\\*Q^(hat)(s', a')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym.envs.registration import register\n",
    "#import readchar\n",
    "\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "\n",
    "arrow_keys = {\n",
    "    '\\x1b[A': UP,\n",
    "    '\\x1b[B': DOWN,\n",
    "    '\\x1b[C': RIGHT,\n",
    "    '\\x1b[D': LEFT\n",
    "}\n",
    "\n",
    "register(\n",
    "    id='FrozenLake-v3',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name': '4x4', \n",
    "            'is_slippery': False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taejunhwang/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')\n",
    "#env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "learning_rate = 0.85\n",
    "dis = 0.99\n",
    "num_episodes = 2000\n",
    "\n",
    "rList = []\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    state = env.reset()\n",
    "    rAll = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = np.argmax(Q[state, :] + np.random.randn(1, env.action_space.n) / (i + 1))\n",
    "        \n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        Q[state, action] = (1-learning_rate)*Q[state, action] + learning_rate*(reward + dis * np.max(Q[new_state, :]))\n",
    "        \n",
    "        rAll += reward\n",
    "        state = new_state\n",
    "        \n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.5\n",
      "Final Q-Table Values\n",
      "[[1.48819449e-01 0.00000000e+00 4.79613481e-03 5.58661906e-03]\n",
      " [0.00000000e+00 4.80008223e-03 0.00000000e+00 4.15455409e-01]\n",
      " [1.56177920e-01 0.00000000e+00 0.00000000e+00 5.97745704e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [7.91794008e-02 5.20922756e-04 3.76232808e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.11897652e-04 2.18290001e-05 1.64899944e-05 5.17245263e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.30451450e-04 5.41730942e-04 6.98261498e-04 3.42784482e-02]\n",
      " [0.00000000e+00 5.12983768e-01 7.17257757e-04 0.00000000e+00]\n",
      " [5.04706918e-02 8.83253337e-05 0.00000000e+00 1.94848185e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.54490172e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 8.57574814e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0f322748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Success rate: \" + str(sum(rList)/num_episodes))\n",
    "print(\"Final Q-Table Values\")\n",
    "print(Q)\n",
    "plt.bar(range(len(rList)), rList, color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic한 환경에서는 Learning Rate가 없이 할 경우 Q-Function을 신뢰하고 Update할 수 없게된다.\n",
    "- action을 취했지만 결과가 다르기 때문, 결과가 다르다는 것은 원하는 기대값을 받지 못한다는 것이고 해당 값으로 Update하면 안된다.\n",
    "\n",
    "따라서 Learning Rate를 적용하여 Q-Function에 의해 Update되는 값의 비중을 조절하여 Optimal한 값을 찾는다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
